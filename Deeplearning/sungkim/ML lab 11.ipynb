{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN\n",
    "\n",
    "- NxN data\n",
    "- filter size = F\n",
    "    - output size = (N-F) / stride + 1\n",
    "    \n",
    "### In practice : Common to zero pad the border\n",
    "- input 7x7\n",
    "- filter 3x3\n",
    "- stride 1\n",
    "- pad with 1 pixel border\n",
    "    - input = 9x9\n",
    "\n",
    "- output = 7x7\n",
    "    - 즉, zero padding을 통해서 입력 이미지와 출력 이미지의 크기를 같게 유지가능\n",
    "\n",
    "ex)\n",
    "32x32x3 image _ 5x5x3 filter1 _ 5x5x3 filter2 _ _ _ _ 5x5x3 filter6\n",
    "activation maps = ( , , 필터갯수) 앞의 두 값은 전체 이미지와 필터 사이즈에 따라 달라짐\n",
    "패딩을 안하면 위의 경우 (28,28,6)이 됨\n",
    "\n",
    "### pooling layer (sampling)\n",
    "- Max pooling\n",
    "    - 4x4 Input\n",
    "    - 2x2 filters\n",
    "    - stride 2\n",
    "        - output = 2x2\n",
    "        - max pooling은 가장 큰 값을 입력하는 방법\n",
    "        \n",
    "### Fully connected layer(FC layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 3, 3, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x15c9330f5c0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQ8AAAD8CAYAAABpXiE9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x15c91286b70>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "image = np.array([[[[1],[2],[3]],\n",
    "                   [[4],[5],[6]], \n",
    "                   [[7],[8],[9]]]], dtype=np.float32)\n",
    "print(image.shape)\n",
    "plt.imshow(image.reshape(3,3), cmap='Greys')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 3, 3, 1)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# filter\n",
    "## ( n, n,color,number)\n",
    "## color = image의 color와 동일"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# conv2d(image, weight, strides, padding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image.shape (1, 3, 3, 1)\n",
      "weight.shape (2, 2, 1, 1)\n"
     ]
    }
   ],
   "source": [
    "print(\"image.shape\", image.shape)\n",
    "weight = tf.constant([[[[1.]],[[1.]]],\n",
    "                      [[[1.]],[[1.]]]])\n",
    "print(\"weight.shape\", weight.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv2d_img.shape (1, 2, 2, 1)\n"
     ]
    }
   ],
   "source": [
    "conv2d = tf.nn.conv2d(image, weight, strides=[1, 1, 1, 1], padding='VALID')\n",
    "conv2d_img = conv2d.eval()\n",
    "print(\"conv2d_img.shape\", conv2d_img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[12. 16.]\n",
      " [24. 28.]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAM0AAAC7CAYAAADGxxq1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\njg2VAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x15c9330fef0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "conv2d_img = np.swapaxes(conv2d_img, 0, 3)\n",
    "for i, one_img in enumerate(conv2d_img):\n",
    "    print(one_img.reshape(2,2))\n",
    "    plt.subplot(1,2,i+1), plt.imshow(one_img.reshape(2,2), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# padding = same 인 경우 input과 output의 크기를 같게 만들겠다라는 의미"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image.shape (1, 3, 3, 1)\n",
      "weight.shape (2, 2, 1, 1)\n"
     ]
    }
   ],
   "source": [
    "print(\"image.shape\", image.shape)\n",
    "\n",
    "weight = tf.constant([[[[1.]],[[1.]]],\n",
    "                      [[[1.]],[[1.]]]])\n",
    "print(\"weight.shape\", weight.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv2d_img.shape (1, 3, 3, 1)\n"
     ]
    }
   ],
   "source": [
    "conv2d = tf.nn.conv2d(image, weight, strides=[1, 1, 1, 1], padding='SAME')\n",
    "conv2d_img = conv2d.eval()\n",
    "print(\"conv2d_img.shape\", conv2d_img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[12. 16.  9.]\n",
      " [24. 28. 15.]\n",
      " [15. 17.  9.]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAMkAAAC7CAYAAADPLLrPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQ2KW+D8H4vpp8cqpkAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x15c9342cd68>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "conv2d_img = np.swapaxes(conv2d_img, 0, 3)\n",
    "for i, one_img in enumerate(conv2d_img):\n",
    "    print(one_img.reshape(3,3))\n",
    "    plt.subplot(1,2,i+1), plt.imshow(one_img.reshape(3,3), cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 filters (2,2,1,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image.shape (1, 3, 3, 1)\n",
      "weight.shape (2, 2, 1, 3)\n"
     ]
    }
   ],
   "source": [
    "print(\"image.shape\", image.shape)\n",
    "\n",
    "weight = tf.constant([[[[1.,10.,-1.]],[[1.,10.,-1.]]],\n",
    "                      [[[1.,10.,-1.]],[[1.,10.,-1.]]]])\n",
    "print(\"weight.shape\", weight.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv2d_img.shape (1, 3, 3, 3)\n"
     ]
    }
   ],
   "source": [
    "conv2d = tf.nn.conv2d(image, weight, strides=[1, 1, 1, 1], padding='SAME')\n",
    "conv2d_img = conv2d.eval()\n",
    "print(\"conv2d_img.shape\", conv2d_img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[12. 16.  9.]\n",
      " [24. 28. 15.]\n",
      " [15. 17.  9.]]\n",
      "[[120. 160.  90.]\n",
      " [240. 280. 150.]\n",
      " [150. 170.  90.]]\n",
      "[[-12. -16.  -9.]\n",
      " [-24. -28. -15.]\n",
      " [-15. -17.  -9.]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAACFCAYAAAB7VhJ6AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nNwAkQ3EDQDIUNwAkQ3EDQDIUNwAk828FNQf8XgjbqwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x15c933875c0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "conv2d_img = np.swapaxes(conv2d_img, 0, 3)\n",
    "for i, one_img in enumerate(conv2d_img):\n",
    "    print(one_img.reshape(3,3))\n",
    "    plt.subplot(1,3,i+1), plt.imshow(one_img.reshape(3,3), cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## max pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1, 1, 1)\n",
      "[[[[4.]]]]\n"
     ]
    }
   ],
   "source": [
    "image = np.array([[[[4],[3]],\n",
    "                    [[2],[1]]]], dtype=np.float32)\n",
    "pool = tf.nn.max_pool(image, ksize=[1, 2, 2, 1],\n",
    "                    strides=[1, 1, 1, 1], padding='VALID')\n",
    "print(pool.shape)\n",
    "print(pool.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 2, 2, 1)\n",
      "[[[[4.]\n",
      "   [3.]]\n",
      "\n",
      "  [[2.]\n",
      "   [1.]]]]\n"
     ]
    }
   ],
   "source": [
    "# padding = same\n",
    "image = np.array([[[[4],[3]],\n",
    "                    [[2],[1]]]], dtype=np.float32)\n",
    "pool = tf.nn.max_pool(image, ksize=[1, 2, 2, 1],\n",
    "                    strides=[1, 1, 1, 1], padding='SAME')\n",
    "print(pool.shape)\n",
    "print(pool.eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mnist Data example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MJ\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-1-69c65344baec>:2: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From C:\\Users\\MJ\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From C:\\Users\\MJ\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\MJ\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\MJ\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\MJ\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x15c96347668>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nDwRF+IGgCD8QFOEHgvp/zdVX5KPezC0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x15c9626e8d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img = mnist.train.images[0].reshape(28,28)\n",
    "plt.imshow(img, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MJ\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py:1662: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n",
      "  warnings.warn('An interactive session is already active. This can '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Conv2D_3:0\", shape=(1, 14, 14, 5), dtype=float32)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAABcCAYAAAB+6068AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nhBDiE/4fWICWGoeDoNwAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x15c96347f98>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "\n",
    "img = img.reshape(-1,28,28,1)\n",
    "# 28x28x1 (1 color)\n",
    "W1 = tf.Variable(tf.random_normal([3, 3, 1, 5], stddev=0.01))\n",
    "# weight는 color을 신경써야함. 3x3 filter, 1 color, 5 filters\n",
    "conv2d = tf.nn.conv2d(img, W1, strides=[1, 2, 2, 1], padding='SAME')\n",
    "# stride는 2x2, pading = same이면, stride가 2이기 때문에, input 사이즈는 1/2\n",
    "print(conv2d)\n",
    "# conv2d. shape = 1x14x14x5\n",
    "sess.run(tf.global_variables_initializer())\n",
    "conv2d_img = conv2d.eval()\n",
    "conv2d_img = np.swapaxes(conv2d_img, 0, 3)\n",
    "for i, one_img in enumerate(conv2d_img):\n",
    "    plt.subplot(1,5,i+1), plt.imshow(one_img.reshape(14,14), cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MNIST max pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"MaxPool_2:0\", shape=(1, 7, 7, 5), dtype=float32)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAABcCAYAAABOZ1+dAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x15c96304ba8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pool = tf.nn.max_pool(conv2d, ksize=[1, 2, 2, 1], strides=[\n",
    "                        1, 2, 2, 1], padding='SAME')\n",
    "# stride = 2x2, padding = same, stride가 2이기 때문에 pool은 input size / 2\n",
    "print(pool)\n",
    "# (1,7,7,5)\n",
    "sess.run(tf.global_variables_initializer())\n",
    "pool_img = pool.eval()\n",
    "pool_img = np.swapaxes(pool_img, 0, 3)\n",
    "for i, one_img in enumerate(pool_img):\n",
    "    plt.subplot(1,5,i+1), plt.imshow(one_img.reshape(7, 7), cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN MNIST exmaple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import random\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "tf.set_random_seed(207)  # reproducibility\n",
    "\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# hyper parameters\n",
    "learning_rate = 0.001\n",
    "training_epochs = 15\n",
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "keep_prob = tf.placeholder(tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, [None, 28*28])\n",
    "X_img = tf.reshape(X, [-1, 28,28, 1]) # 28x28x1   28x28 size & 1 color\n",
    "Y = tf.placeholder(tf.float32, [None, 10]) # labels = 0~9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fist conv layer\n",
    "W1 = tf.Variable(tf.random_normal([3,3,1,32], stddev=0.01))\n",
    "# filter = 3x3, 1 color, filter number = 32\n",
    "# Conv -> (?, 28, 28, 32) # padding=SAME 이기 때문에 28x28 유지, 32개 필터\n",
    "# Poll -> (?, 14, 14, 32) # stride가 2이고, padding=SAME이기 때문에 28x28 -> 14x14\n",
    "L1 = tf.nn.conv2d(X_img, W1, strides=[1,1,1,1], padding=\"SAME\")\n",
    "L1 = tf.nn.relu(L1)\n",
    "L1 = tf.nn.max_pool(L1, ksize=[1,2,2,1], strides=[1,2,2,1], padding=\"SAME\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# second conv layer\n",
    "W2 = tf.Variable(tf.random_normal([3,3,32,64], stddev=0.01))\n",
    "# 3x3 filter, 32는 first conv 에서 오는 32개 필터, 64는 새로운 필터의 개수\n",
    "# Conv -> (?, 14, 14, 64)\n",
    "# pool -> (?, 7, 7, 64)\n",
    "L2 = tf.nn.conv2d(L1, W2, strides=[1,1,1,1], padding=\"SAME\")\n",
    "L2 = tf.nn.max_pool(L2, ksize=[1,2,2,1], strides=[1,2,2,1], padding=\"SAME\")\n",
    "# size = 2x2, stride = 2x2\n",
    "L2 = tf.reshape(L2, [-1, 7*7*64])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# FC layer\n",
    "# Final FC 7x7x64 inputs -> 10 outputs(0~9)\n",
    "W3 = tf.get_variable(\"W3\", shape=[7 * 7 * 64, 10],\n",
    "                     initializer=tf.contrib.layers.xavier_initializer())\n",
    "b = tf.Variable(tf.random_normal([10]))\n",
    "logits = tf.matmul(L2, W3) + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=logits, labels=Y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# initialize\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning started. It takes sometime.\n",
      "Epoch: 0001 cost = 0.365848373\n",
      "Epoch: 0002 cost = 0.112622599\n",
      "Epoch: 0003 cost = 0.078331181\n",
      "Epoch: 0004 cost = 0.064425407\n",
      "Epoch: 0005 cost = 0.053574341\n",
      "Epoch: 0006 cost = 0.048294075\n",
      "Epoch: 0007 cost = 0.043377898\n",
      "Epoch: 0008 cost = 0.037750552\n",
      "Epoch: 0009 cost = 0.033935846\n",
      "Epoch: 0010 cost = 0.030276788\n",
      "Epoch: 0011 cost = 0.027562464\n",
      "Epoch: 0012 cost = 0.023947605\n",
      "Epoch: 0013 cost = 0.022409607\n",
      "Epoch: 0014 cost = 0.020103913\n",
      "Epoch: 0015 cost = 0.017979104\n",
      "Learning Finished!\n",
      "Accuracy: 0.9835\n"
     ]
    }
   ],
   "source": [
    "# train my model\n",
    "print('Learning started. It takes sometime.')\n",
    "for epoch in range(training_epochs):\n",
    "    avg_cost = 0\n",
    "    total_batch = int(mnist.train.num_examples / batch_size)\n",
    "\n",
    "    for i in range(total_batch):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "        feed_dict = {X: batch_xs, Y: batch_ys}\n",
    "        c, _ = sess.run([cost, optimizer], feed_dict=feed_dict)\n",
    "        avg_cost += c / total_batch\n",
    "\n",
    "    print('Epoch:', '%04d' % (epoch + 1), 'cost =', '{:.9f}'.format(avg_cost))\n",
    "\n",
    "print('Learning Finished!')\n",
    "\n",
    "# Test model and check accuracy\n",
    "correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "print('Accuracy:', sess.run(accuracy, feed_dict={\n",
    "      X: mnist.test.images, Y: mnist.test.labels}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MJ\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-1-d63ba6a5d030>:8: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From C:\\Users\\MJ\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From C:\\Users\\MJ\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\MJ\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\MJ\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\MJ\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "tf.set_random_seed(207)  # reproducibility\n",
    "\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# hyper parameters\n",
    "learning_rate = 0.001\n",
    "training_epochs = 15\n",
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "keep_prob = tf.placeholder(tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, [None, 28*28])\n",
    "X_img = tf.reshape(X, [-1,28,28,1]) # img 28x28x1 (1 color)\n",
    "Y = tf.placeholder(tf.float32, [None, 10]) # labels = 0~9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# layer 1\n",
    "W1 = tf.Variable(tf.random_normal([3,3,1,32], stddev=0.01))\n",
    "# Conv -> [?,28,28,32]\n",
    "# Pool -> [?,14,14,32]\n",
    "L1 = tf.nn.conv2d(X_img, W1, strides=[1,1,1,1], padding=\"SAME\")\n",
    "L1 = tf.nn.relu(L1)\n",
    "L1 = tf.nn.max_pool(L1, ksize=[1,2,2,1], strides=[1,2,2,1], padding=\"SAME\")\n",
    "L1 = tf.nn.dropout(L1, keep_prob=keep_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# layer 2\n",
    "W2 = tf.Variable(tf.random_normal([3,3,32,64], stddev=0.01))\n",
    "# Conv -> [? , 14,14, 64]\n",
    "# pool -> [?, 7, 7, 64]\n",
    "L2 = tf.nn.conv2d(L1, W2, strides=[1,1,1,1], padding=\"SAME\")\n",
    "L2 = tf.nn.relu(L2)\n",
    "L2 = tf.nn.max_pool(L2, ksize=[1,2,2,1], strides=[1,2,2,1], padding=\"SAME\")\n",
    "L2 = tf.nn.dropout(L2, keep_prob=keep_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# layer 3\n",
    "W3 = tf.Variable(tf.random_normal([3,3,64,128], stddev=0.01))\n",
    "# Conv = [?, 7, 7, 128]\n",
    "# Pool = [?, 4, 4, 128]\n",
    "# reshape = [?, 4*4*128] # flatten for FC\n",
    "L3 = tf.nn.conv2d(L2, W3, strides=[1,1,1,1], padding=\"SAME\")\n",
    "L3 = tf.nn.relu(L3)\n",
    "L3 = tf.nn.max_pool(L3, ksize=[1,2,2,1], strides=[1,2,2,1], padding=\"SAME\")\n",
    "L3 = tf.nn.dropout(L3, keep_prob=keep_prob)\n",
    "L3_flat = tf.reshape(L3, [-1, 4*4*128])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# layer4 = FC\n",
    "# FC 4x4x128 inputs -> 625 outputs\n",
    "W4 = tf.get_variable(\"W4\", shape=[128*4*4, 625],\n",
    "                    initializer=tf.contrib.layers.xavier_initializer())\n",
    "b4 = tf.Variable(tf.random_normal([625]))\n",
    "L4 = tf.nn.relu(tf.matmul(L3_flat, W4)+ b4)\n",
    "Lt = tf.nn.dropout(L4, keep_prob=keep_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# layer5 = FC\n",
    "# 625 inputs -> 10 outputs\n",
    "W5 = tf.get_variable(\"W5\", shape=[625, 10],\n",
    "                    initializer=tf.contrib.layers.xavier_initializer())\n",
    "b5 = tf.Variable(tf.random_normal([10]))\n",
    "logits = tf.matmul(L4, W5)+b5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=logits, labels=Y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deep learning start. It takes sometime.\n",
      "Epoch: 0001 cost: 0.019095502\n",
      "Epoch: 0002 cost: 0.018910083\n",
      "Epoch: 0003 cost: 0.017512476\n",
      "Epoch: 0004 cost: 0.019057623\n",
      "Epoch: 0005 cost: 0.016228629\n",
      "Epoch: 0006 cost: 0.017249899\n",
      "Epoch: 0007 cost: 0.014868043\n",
      "Epoch: 0008 cost: 0.016490480\n",
      "Epoch: 0009 cost: 0.015332666\n",
      "Epoch: 0010 cost: 0.015066526\n",
      "Epoch: 0011 cost: 0.014114765\n",
      "Epoch: 0012 cost: 0.013655855\n",
      "Epoch: 0013 cost: 0.012106912\n",
      "Epoch: 0014 cost: 0.014994144\n",
      "Epoch: 0015 cost: 0.013299803\n",
      "Deep learning End\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'DataSet' object has no attribute 'image'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-bcc4dc81da3d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[0mcorrect_prediction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mequal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[0maccuracy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreduce_mean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcorrect_prediction\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Accuracy:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mmnist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mmnist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeep_prob\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'DataSet' object has no attribute 'image'"
     ]
    }
   ],
   "source": [
    "print(\"Deep learning start. It takes sometime.\")\n",
    "for epoch in range(training_epochs):\n",
    "    avg_cost = 0\n",
    "    total_batch = int(mnist.train.num_examples / batch_size)\n",
    "    \n",
    "    for i in range(total_batch):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "        feed_dict = {X:batch_xs, Y:batch_ys, keep_prob:0.7}\n",
    "        c, _ = sess.run([cost, optimizer], feed_dict=feed_dict)\n",
    "        avg_cost += c / total_batch\n",
    "    print(\"Epoch:\", \"%04d\" % (epoch + 1), 'cost:', '{:.9f}'.format(avg_cost))\n",
    "    \n",
    "print('Deep learning End')\n",
    "\n",
    "correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(Y,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "print(\"Accuracy:\", sess.run(accuracy, feed_dict={X:mnist.test.images, Y:mnist.test.labels, keep_prob:1}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9935\n"
     ]
    }
   ],
   "source": [
    "correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(Y,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "print(\"Accuracy:\", sess.run(accuracy, feed_dict={X:mnist.test.images, Y:mnist.test.labels, keep_prob:1}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN using CLASS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# hyper parameters\n",
    "learning_rate = 0.001\n",
    "training_epochs = 15\n",
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Model:\n",
    "    \n",
    "    def __init__(self, sess, name):\n",
    "        self.sess = sess\n",
    "        self.name = name\n",
    "        self._build_net()\n",
    "        \n",
    "    def _build_net(self):\n",
    "        with tf.variable_scope(self.name):\n",
    "            # dropout (=keep_prob) rate : 0.5~07 on training, should be 1 for testing\n",
    "            self.keep_prob = tf.placeholder(tf.float32)\n",
    "            \n",
    "            # input\n",
    "            self.X = tf.placeholder(tf.float32, [None, 28*28])\n",
    "            X_img = tf.reshape(self.X, [-1, 28,28,1])\n",
    "            self.Y = tf.placeholder(tf.float32, [None, 10])\n",
    "            \n",
    "            # layer 1\n",
    "            W1 = tf.Variable(tf.random_normal([3,3,1,32], stddev=0.01))\n",
    "            L1 = tf.nn.conv2d(X_img, W1, strides=[1,1,1,1], padding=\"SAME\")\n",
    "            L1 = tf.nn.relu(L1)\n",
    "            L1 = tf.nn.max_pool(L1, ksize=[1,2,2,1], strides=[1,2,2,1], padding=\"SAME\")\n",
    "            L1 = tf.nn.dropout(L1, keep_prob=self.keep_prob)\n",
    "            \n",
    "            # layer 2\n",
    "            W2 = tf.Variable(tf.random_normal([3,3,32,64], stddev=0.01))\n",
    "            L2 = tf.nn.conv2d(L1, W2, strides=[1,1,1,1], padding=\"SAME\")\n",
    "            L2 = tf.nn.relu(L2)\n",
    "            L2 = tf.nn.max_pool(L2, ksize=[1,2,2,1], strides=[1,2,2,1], padding=\"SAME\")\n",
    "            L2 = tf.nn.dropout(L2, keep_prob=self.keep_prob)\n",
    "            \n",
    "            # layer 3\n",
    "            W3 = tf.Variable(tf.random_normal([3,3,64,128], stddev=0.01))\n",
    "            L3 = tf.nn.conv2d(L2, W3, strides=[1,1,1,1], padding=\"SAME\")\n",
    "            L3 = tf.nn.relu(L3)\n",
    "            L3 = tf.nn.max_pool(L3, ksize=[1,2,2,1], strides=[1,2,2,1], padding=\"SAME\")\n",
    "            L3 = tf.nn.dropout(L3, keep_prob=self.keep_prob)\n",
    "            \n",
    "            L3_flat = tf.reshape(L3, [-1, 4*4*128])\n",
    "            \n",
    "            # layer 4 = FC\n",
    "            ## final layer / input = 4*4*128 _ output = 625\n",
    "            W4 = tf.get_variable(\"W4\", shape=[128*4*4, 625],\n",
    "                                initializer = tf.contrib.layers.xavier_initializer())\n",
    "            b4 = tf.Variable(tf.random_normal([625]))\n",
    "            L4 = tf.nn.relu(tf.matmul(L3_flat, W4)+b4)\n",
    "            L4 = tf.nn.dropout(L4, keep_prob=self.keep_prob)\n",
    "            \n",
    "            # layer 5 = FC\n",
    "            ## final layer / input = 625 _ output = 10\n",
    "            W5 = tf.get_variable(\"W5\", shape=[625, 10],\n",
    "                                initializer = tf.contrib.layers.xavier_initializer())\n",
    "            b5 = tf.Variable(tf.random_normal([10]))\n",
    "            self.logits = tf.matmul(L4, W5)+b5\n",
    "            \n",
    "            # cost / optimizer\n",
    "        self.cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(\n",
    "        logits=self.logits, labels=self.Y))\n",
    "        self.optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(self.cost)\n",
    "            \n",
    "        correct_prediction = tf.equal(tf.argmax(self.logits,1), tf.argmax(self.Y, 1))\n",
    "        self.accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "            \n",
    "    def predict(self, x_test, keep_prop=1.0):\n",
    "        return self.sess.run(self.logits, feed_dict={self.X: x_test, \n",
    "                                                         self.keep_prob:keep_prop})\n",
    "        \n",
    "    def get_accuracy(self, x_test, y_test, keep_prop=1.0):\n",
    "        return self.sess.run(self.accuracy, feed_dict={self.X: x_test,\n",
    "                                                          self.Y: y_test,\n",
    "                                                          self.keep_prob:keep_prop})\n",
    "        \n",
    "    def train(self, x_data, y_data, keep_prop=0.7):\n",
    "        return self.sess.run([self.cost, self.optimizer], feed_dict={\n",
    "                self.X: x_data, self.Y: y_data, self.keep_prob: keep_prop})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Model:\n",
    "\n",
    "    def __init__(self, sess, name):\n",
    "        self.sess = sess\n",
    "        self.name = name\n",
    "        self._build_net()\n",
    "\n",
    "    def _build_net(self):\n",
    "        with tf.variable_scope(self.name):\n",
    "            # dropout (keep_prob) rate  0.7~0.5 on training, but should be 1\n",
    "            # for testing\n",
    "            self.keep_prob = tf.placeholder(tf.float32)\n",
    "\n",
    "            # input place holders\n",
    "            self.X = tf.placeholder(tf.float32, [None, 784])\n",
    "            # img 28x28x1 (black/white)\n",
    "            X_img = tf.reshape(self.X, [-1, 28, 28, 1])\n",
    "            self.Y = tf.placeholder(tf.float32, [None, 10])\n",
    "\n",
    "            # L1 ImgIn shape=(?, 28, 28, 1)\n",
    "            W1 = tf.Variable(tf.random_normal([3, 3, 1, 32], stddev=0.01))\n",
    "            #    Conv     -> (?, 28, 28, 32)\n",
    "            #    Pool     -> (?, 14, 14, 32)\n",
    "            L1 = tf.nn.conv2d(X_img, W1, strides=[1, 1, 1, 1], padding='SAME')\n",
    "            L1 = tf.nn.relu(L1)\n",
    "            L1 = tf.nn.max_pool(L1, ksize=[1, 2, 2, 1],\n",
    "                                strides=[1, 2, 2, 1], padding='SAME')\n",
    "            L1 = tf.nn.dropout(L1, keep_prob=self.keep_prob)\n",
    "            '''\n",
    "            Tensor(\"Conv2D:0\", shape=(?, 28, 28, 32), dtype=float32)\n",
    "            Tensor(\"Relu:0\", shape=(?, 28, 28, 32), dtype=float32)\n",
    "            Tensor(\"MaxPool:0\", shape=(?, 14, 14, 32), dtype=float32)\n",
    "            Tensor(\"dropout/mul:0\", shape=(?, 14, 14, 32), dtype=float32)\n",
    "            '''\n",
    "\n",
    "            # L2 ImgIn shape=(?, 14, 14, 32)\n",
    "            W2 = tf.Variable(tf.random_normal([3, 3, 32, 64], stddev=0.01))\n",
    "            #    Conv      ->(?, 14, 14, 64)\n",
    "            #    Pool      ->(?, 7, 7, 64)\n",
    "            L2 = tf.nn.conv2d(L1, W2, strides=[1, 1, 1, 1], padding='SAME')\n",
    "            L2 = tf.nn.relu(L2)\n",
    "            L2 = tf.nn.max_pool(L2, ksize=[1, 2, 2, 1],\n",
    "                                strides=[1, 2, 2, 1], padding='SAME')\n",
    "            L2 = tf.nn.dropout(L2, keep_prob=self.keep_prob)\n",
    "            '''\n",
    "            Tensor(\"Conv2D_1:0\", shape=(?, 14, 14, 64), dtype=float32)\n",
    "            Tensor(\"Relu_1:0\", shape=(?, 14, 14, 64), dtype=float32)\n",
    "            Tensor(\"MaxPool_1:0\", shape=(?, 7, 7, 64), dtype=float32)\n",
    "            Tensor(\"dropout_1/mul:0\", shape=(?, 7, 7, 64), dtype=float32)\n",
    "            '''\n",
    "\n",
    "            # L3 ImgIn shape=(?, 7, 7, 64)\n",
    "            W3 = tf.Variable(tf.random_normal([3, 3, 64, 128], stddev=0.01))\n",
    "            #    Conv      ->(?, 7, 7, 128)\n",
    "            #    Pool      ->(?, 4, 4, 128)\n",
    "            #    Reshape   ->(?, 4 * 4 * 128) # Flatten them for FC\n",
    "            L3 = tf.nn.conv2d(L2, W3, strides=[1, 1, 1, 1], padding='SAME')\n",
    "            L3 = tf.nn.relu(L3)\n",
    "            L3 = tf.nn.max_pool(L3, ksize=[1, 2, 2, 1], strides=[\n",
    "                                1, 2, 2, 1], padding='SAME')\n",
    "            L3 = tf.nn.dropout(L3, keep_prob=self.keep_prob)\n",
    "\n",
    "            L3_flat = tf.reshape(L3, [-1, 128 * 4 * 4])\n",
    "            '''\n",
    "            Tensor(\"Conv2D_2:0\", shape=(?, 7, 7, 128), dtype=float32)\n",
    "            Tensor(\"Relu_2:0\", shape=(?, 7, 7, 128), dtype=float32)\n",
    "            Tensor(\"MaxPool_2:0\", shape=(?, 4, 4, 128), dtype=float32)\n",
    "            Tensor(\"dropout_2/mul:0\", shape=(?, 4, 4, 128), dtype=float32)\n",
    "            Tensor(\"Reshape_1:0\", shape=(?, 2048), dtype=float32)\n",
    "            '''\n",
    "\n",
    "            # L4 FC 4x4x128 inputs -> 625 outputs\n",
    "            W4 = tf.get_variable(\"W4\", shape=[128 * 4 * 4, 625],\n",
    "                                 initializer=tf.contrib.layers.xavier_initializer())\n",
    "            b4 = tf.Variable(tf.random_normal([625]))\n",
    "            L4 = tf.nn.relu(tf.matmul(L3_flat, W4) + b4)\n",
    "            L4 = tf.nn.dropout(L4, keep_prob=self.keep_prob)\n",
    "            '''\n",
    "            Tensor(\"Relu_3:0\", shape=(?, 625), dtype=float32)\n",
    "            Tensor(\"dropout_3/mul:0\", shape=(?, 625), dtype=float32)\n",
    "            '''\n",
    "\n",
    "            # L5 Final FC 625 inputs -> 10 outputs\n",
    "            W5 = tf.get_variable(\"W5\", shape=[625, 10],\n",
    "                                 initializer=tf.contrib.layers.xavier_initializer())\n",
    "            b5 = tf.Variable(tf.random_normal([10]))\n",
    "            self.logits = tf.matmul(L4, W5) + b5\n",
    "            '''\n",
    "            Tensor(\"add_1:0\", shape=(?, 10), dtype=float32)\n",
    "            '''\n",
    "\n",
    "        # define cost/loss & optimizer\n",
    "        self.cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n",
    "            logits=self.logits, labels=self.Y))\n",
    "        self.optimizer = tf.train.AdamOptimizer(\n",
    "            learning_rate=learning_rate).minimize(self.cost)\n",
    "\n",
    "        correct_prediction = tf.equal(\n",
    "            tf.argmax(self.logits, 1), tf.argmax(self.Y, 1))\n",
    "        self.accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "    def predict(self, x_test, keep_prop=1.0):\n",
    "        return self.sess.run(self.logits, feed_dict={self.X: x_test, self.keep_prob: keep_prop})\n",
    "\n",
    "    def get_accuracy(self, x_test, y_test, keep_prop=1.0):\n",
    "        return self.sess.run(self.accuracy, feed_dict={self.X: x_test, self.Y: y_test, self.keep_prob: keep_prop})\n",
    "\n",
    "    def train(self, x_data, y_data, keep_prop=0.7):\n",
    "        return self.sess.run([self.cost, self.optimizer], feed_dict={\n",
    "            self.X: x_data, self.Y: y_data, self.keep_prob: keep_prop})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-14-cd79db8f3275>:94: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "m1 = Model(sess, \"m1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deeplearning Start\n",
      "Epoch: 0001 cost: 0.418834060\n",
      "Epoch: 0002 cost: 0.092228168\n",
      "Epoch: 0003 cost: 0.068900539\n",
      "Epoch: 0004 cost: 0.058053490\n",
      "Epoch: 0005 cost: 0.049416524\n",
      "Epoch: 0006 cost: 0.044746012\n",
      "Epoch: 0007 cost: 0.041444015\n",
      "Epoch: 0008 cost: 0.039242452\n",
      "Epoch: 0009 cost: 0.034758848\n",
      "Epoch: 0010 cost: 0.033500357\n",
      "Epoch: 0011 cost: 0.029538118\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-d19921dfd576>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtotal_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[0mbatch_xs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_ys\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmnist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnext_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m         \u001b[0mc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mm1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_xs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_ys\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m         \u001b[0mavg_cost\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mc\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mtotal_batch\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-14-cd79db8f3275>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, x_data, y_data, keep_prop)\u001b[0m\n\u001b[0;32m    108\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeep_prop\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.7\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    109\u001b[0m         return self.sess.run([self.cost, self.optimizer], feed_dict={\n\u001b[1;32m--> 110\u001b[1;33m             self.X: x_data, self.Y: y_data, self.keep_prob: keep_prop})\n\u001b[0m",
      "\u001b[1;32mC:\\Users\\MJ\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    885\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    886\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 887\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    888\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    889\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\MJ\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1108\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1109\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1110\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1111\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1112\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\MJ\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1284\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1285\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1286\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1287\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1288\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\MJ\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1290\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1291\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1292\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1293\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1294\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\MJ\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1275\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1276\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1277\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1278\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1279\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\MJ\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1365\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[0;32m   1366\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1367\u001b[1;33m         run_metadata)\n\u001b[0m\u001b[0;32m   1368\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1369\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(\"Deeplearning Start\")\n",
    "for epoch in range(training_epochs):\n",
    "    avg_cost = 0\n",
    "    total_batch = int(mnist.train.num_examples / batch_size)\n",
    "    \n",
    "    for i in range(total_batch):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "        c, _ = m1.train(batch_xs, batch_ys)\n",
    "        avg_cost += c / total_batch\n",
    "        \n",
    "    print(\"Epoch:\", \"%04d\" % (epoch + 1), 'cost:', '{:.9f}'.format(avg_cost))\n",
    "    \n",
    "print('Deep learning End')\n",
    "\n",
    "print(\"Accuracy:\", m1.get_accuracy(mnist.test.images, mnist.test.labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "250px",
    "left": "589px",
    "right": "20px",
    "top": "120px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
