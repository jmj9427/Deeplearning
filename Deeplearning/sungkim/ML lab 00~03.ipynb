{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MJ\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.11.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hello = tf.constant(\"Hello, TensorFlow!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- constant를 만들고 hello라는 노드로 입력"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- tensorflow에서는 sess를 만들고 sess.run을 해줘야 함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'Hello, TensorFlow!'\n"
     ]
    }
   ],
   "source": [
    "print(sess.run(hello))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- b는 bytes literals 이라는 의미"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computational Graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- +로 이어지는 노드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "node1 = tf.constant(3.0, tf.float32)\n",
    "node2 = tf.constant(4.0) # also tf.float32 implicitly\n",
    "node3 = tf.add(node1, node2) # node3 = node1 + node2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "node1: Tensor(\"Const_3:0\", shape=(), dtype=float32) node2: Tensor(\"Const_4:0\", shape=(), dtype=float32)\n",
      "node3: Tensor(\"Add_1:0\", shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(\"node1:\", node1, \"node2:\", node2)\n",
    "print(\"node3:\", node3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 그냥 출력하면, 각각의 tensor로 인식을 하고 결과값을 출력하진 않음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sess.run(node1,node2): [3.0, 4.0]\n",
      "sess.run(node3): 7.0\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "print(\"sess.run(node1,node2):\", sess.run([node1, node2]))\n",
    "print(\"sess.run(node3):\", sess.run(node3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- tensorflow의 전체 구조는\n",
    "1) graph를 build\n",
    "2) sess.run() 을 통해서 진행\n",
    "3) value update 진행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 1) build grahp(tensors) using TensorFlow operation\n",
    "# 2) feed data and run graph(operation) = sess.run(operation)\n",
    "# 3) update variables in the graph(and return values0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### graph를 만들고, 실행할때 값으로 주고싶다\n",
    "- placeholder 이용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = tf.placeholder(tf.float32)\n",
    "b = tf.placeholder(tf.float32)\n",
    "adder_node = a + b # + provides a shortcut for tf.add(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.5\n",
      "[3. 7.]\n"
     ]
    }
   ],
   "source": [
    "print(sess.run(adder_node, feed_dict={a:3, b:4.5}))\n",
    "print(sess.run(adder_node, feed_dict={a:[1,3], b:[2,4]}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- array로 placeholder에 넣어줄 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5. 7.]\n"
     ]
    }
   ],
   "source": [
    "print(sess.run(adder_node, feed_dict={a:3, b:[2,4]}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- a가 한개인 경우는 반복으로 입력됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 1) build grahp(tensors) using TensorFlow operation _ placeholder\n",
    "# 2) feed data and run graph(operation) = sess.run(operation, feed_dict={x : x_data})\n",
    "# 3) update variables in the graph(and return values0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.1 Tensor Ranks, shapes and types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## scalar(magnitude only)\n",
    "- rank = 0, math entity = Scalar, ex) s=483\n",
    "\n",
    "## vector(magnitude and direction)\n",
    "- rank = 1, math entity = vector, ex) v = [1.1, 2.2, 3.3]\n",
    "\n",
    "## matrix(table of numbers)\n",
    "- rank = 2, math entity = matrix, ex) m = [[1,2,3], [4,5,6], [7,8,9]]\n",
    "\n",
    "## 3-tensor(cube of numbers)\n",
    "- rank = 3, math entity = 3-tensor, ex) t = [[[2], [4], [6]],[[8], [10], [12]], [[14], [16], [18]]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.2 tensor shape & type\n",
    "- shape 파악과 type 파악에 주의!\n",
    "    - type은 보통 float32 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Regression\n",
    "- H(x) = Wx + b\n",
    "    - which hypothesis is better??\n",
    "    \n",
    "        - 실제 데이터와 직선간의 거리로 계산\n",
    "        \n",
    "        - 가설과 실제 데이터간의 거리 계산 = cost function(=loss function)\n",
    "        \n",
    "        - (H(x) - y)^2 _ 차이가 - +에 상관없이 양수로 표현가능,\n",
    "             차이가 클때 더 큰 penalty 부과\n",
    "        \n",
    "        - cost = 1/m * sigma((H(x_i) - y_i)^2)   m = number of data\n",
    "             objective = minimize cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# X and Y data\n",
    "x_train = [1, 2, 3]\n",
    "y_train = [1, 2, 3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variable = trainable variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = tf.Variable(tf.random_normal([1]), name=\"weight\") # shape = rank가 1인 array\n",
    "b = tf.Variable(tf.random_normal([1]), name=\"bias\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hypothesis = x_train * W + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define cost/loss function\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- tf.reduce_mean = 평균을 내주는 함수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- minimize == GradientDescent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = optimizer.minimize(cost) # train이라는 node 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 0 cost: 7.667603e-06 W: [1.0032161] b: [-0.00731093]\n",
      "step: 20 cost: 6.9638686e-06 W: [1.003065] b: [-0.00696735]\n",
      "step: 40 cost: 6.3247176e-06 W: [1.002921] b: [-0.00663994]\n",
      "step: 60 cost: 5.7444927e-06 W: [1.0027838] b: [-0.00632792]\n",
      "step: 80 cost: 5.2173186e-06 W: [1.0026529] b: [-0.0060306]\n",
      "step: 100 cost: 4.738467e-06 W: [1.0025283] b: [-0.00574721]\n",
      "step: 120 cost: 4.303268e-06 W: [1.0024093] b: [-0.00547712]\n",
      "step: 140 cost: 3.9085307e-06 W: [1.0022962] b: [-0.0052197]\n",
      "step: 160 cost: 3.5500589e-06 W: [1.0021883] b: [-0.00497444]\n",
      "step: 180 cost: 3.2240284e-06 W: [1.0020856] b: [-0.00474071]\n",
      "step: 200 cost: 2.928329e-06 W: [1.0019876] b: [-0.00451797]\n",
      "step: 220 cost: 2.6597008e-06 W: [1.0018941] b: [-0.00430567]\n",
      "step: 240 cost: 2.4153805e-06 W: [1.0018051] b: [-0.00410335]\n",
      "step: 260 cost: 2.1937042e-06 W: [1.0017203] b: [-0.00391056]\n",
      "step: 280 cost: 1.9925874e-06 W: [1.0016396] b: [-0.0037268]\n",
      "step: 300 cost: 1.8096416e-06 W: [1.0015624] b: [-0.00355172]\n",
      "step: 320 cost: 1.6437237e-06 W: [1.0014892] b: [-0.00338487]\n",
      "step: 340 cost: 1.4928602e-06 W: [1.0014191] b: [-0.00322586]\n",
      "step: 360 cost: 1.3558841e-06 W: [1.0013525] b: [-0.00307434]\n",
      "step: 380 cost: 1.231638e-06 W: [1.0012891] b: [-0.00292998]\n",
      "step: 400 cost: 1.11869e-06 W: [1.0012286] b: [-0.00279241]\n",
      "step: 420 cost: 1.0161501e-06 W: [1.0011708] b: [-0.00266129]\n",
      "step: 440 cost: 9.227499e-07 W: [1.0011157] b: [-0.00253632]\n",
      "step: 460 cost: 8.3814075e-07 W: [1.0010633] b: [-0.00241722]\n",
      "step: 480 cost: 7.6133705e-07 W: [1.0010134] b: [-0.00230373]\n",
      "step: 500 cost: 6.9154845e-07 W: [1.0009658] b: [-0.00219557]\n",
      "step: 520 cost: 6.2812364e-07 W: [1.0009205] b: [-0.00209254]\n",
      "step: 540 cost: 5.705474e-07 W: [1.0008774] b: [-0.0019943]\n",
      "step: 560 cost: 5.182971e-07 W: [1.0008364] b: [-0.00190069]\n",
      "step: 580 cost: 4.707239e-07 W: [1.0007972] b: [-0.00181146]\n",
      "step: 600 cost: 4.2762744e-07 W: [1.0007596] b: [-0.00172643]\n",
      "step: 620 cost: 3.8836552e-07 W: [1.0007238] b: [-0.00164546]\n",
      "step: 640 cost: 3.5290066e-07 W: [1.0006902] b: [-0.00156829]\n",
      "step: 660 cost: 3.2057642e-07 W: [1.0006577] b: [-0.00149469]\n",
      "step: 680 cost: 2.9119332e-07 W: [1.0006267] b: [-0.00142461]\n",
      "step: 700 cost: 2.645244e-07 W: [1.0005976] b: [-0.00135776]\n",
      "step: 720 cost: 2.401754e-07 W: [1.0005692] b: [-0.00129407]\n",
      "step: 740 cost: 2.1829783e-07 W: [1.0005429] b: [-0.00123342]\n",
      "step: 760 cost: 1.9826733e-07 W: [1.0005171] b: [-0.00117551]\n",
      "step: 780 cost: 1.8014015e-07 W: [1.0004933] b: [-0.0011205]\n",
      "step: 800 cost: 1.6365784e-07 W: [1.0004698] b: [-0.00106794]\n",
      "step: 820 cost: 1.48681e-07 W: [1.0004481] b: [-0.00101792]\n",
      "step: 840 cost: 1.3500788e-07 W: [1.0004267] b: [-0.00097021]\n",
      "step: 860 cost: 1.2267803e-07 W: [1.0004071] b: [-0.00092467]\n",
      "step: 880 cost: 1.1147855e-07 W: [1.000388] b: [-0.00088149]\n",
      "step: 900 cost: 1.01217864e-07 W: [1.0003695] b: [-0.00084008]\n",
      "step: 920 cost: 9.2009486e-08 W: [1.0003526] b: [-0.00080076]\n",
      "step: 940 cost: 8.359836e-08 W: [1.0003359] b: [-0.00076337]\n",
      "step: 960 cost: 7.594871e-08 W: [1.0003201] b: [-0.00072746]\n",
      "step: 980 cost: 6.9027685e-08 W: [1.0003054] b: [-0.00069343]\n",
      "step: 1000 cost: 6.2724155e-08 W: [1.0002911] b: [-0.00066113]\n",
      "step: 1020 cost: 5.6932695e-08 W: [1.000277] b: [-0.00063008]\n",
      "step: 1040 cost: 5.1724754e-08 W: [1.0002644] b: [-0.00060049]\n",
      "step: 1060 cost: 4.705422e-08 W: [1.0002522] b: [-0.00057251]\n",
      "step: 1080 cost: 4.274247e-08 W: [1.0002403] b: [-0.00054587]\n",
      "step: 1100 cost: 3.8802046e-08 W: [1.0002286] b: [-0.00052019]\n",
      "step: 1120 cost: 3.526253e-08 W: [1.0002182] b: [-0.00049573]\n",
      "step: 1140 cost: 3.2052025e-08 W: [1.0002083] b: [-0.00047258]\n",
      "step: 1160 cost: 2.9166381e-08 W: [1.0001987] b: [-0.00045071]\n",
      "step: 1180 cost: 2.6478617e-08 W: [1.0001892] b: [-0.00042977]\n",
      "step: 1200 cost: 2.4038542e-08 W: [1.00018] b: [-0.00040949]\n",
      "step: 1220 cost: 2.1830024e-08 W: [1.0001717] b: [-0.0003902]\n",
      "step: 1240 cost: 1.9847548e-08 W: [1.0001639] b: [-0.00037195]\n",
      "step: 1260 cost: 1.8057417e-08 W: [1.0001564] b: [-0.00035469]\n",
      "step: 1280 cost: 1.64432e-08 W: [1.0001493] b: [-0.00033835]\n",
      "step: 1300 cost: 1.495197e-08 W: [1.0001421] b: [-0.00032269]\n",
      "step: 1320 cost: 1.3560619e-08 W: [1.0001351] b: [-0.00030748]\n",
      "step: 1340 cost: 1.2311308e-08 W: [1.0001287] b: [-0.00029288]\n",
      "step: 1360 cost: 1.1165876e-08 W: [1.0001228] b: [-0.00027908]\n",
      "step: 1380 cost: 1.0147328e-08 W: [1.0001172] b: [-0.00026603]\n",
      "step: 1400 cost: 9.238003e-09 W: [1.0001118] b: [-0.00025369]\n",
      "step: 1420 cost: 8.410761e-09 W: [1.0001068] b: [-0.00024201]\n",
      "step: 1440 cost: 7.660443e-09 W: [1.000102] b: [-0.00023096]\n",
      "step: 1460 cost: 6.9831096e-09 W: [1.0000973] b: [-0.00022042]\n",
      "step: 1480 cost: 6.336967e-09 W: [1.0000925] b: [-0.00021021]\n",
      "step: 1500 cost: 5.7423235e-09 W: [1.0000877] b: [-0.00020022]\n",
      "step: 1520 cost: 5.2139533e-09 W: [1.0000837] b: [-0.0001906]\n",
      "step: 1540 cost: 4.7316617e-09 W: [1.0000798] b: [-0.00018151]\n",
      "step: 1560 cost: 4.292044e-09 W: [1.000076] b: [-0.00017292]\n",
      "step: 1580 cost: 3.9037893e-09 W: [1.0000726] b: [-0.00016479]\n",
      "step: 1600 cost: 3.5417809e-09 W: [1.0000691] b: [-0.0001571]\n",
      "step: 1620 cost: 3.2270293e-09 W: [1.000066] b: [-0.00014982]\n",
      "step: 1640 cost: 2.9320877e-09 W: [1.0000632] b: [-0.00014295]\n",
      "step: 1660 cost: 2.6775488e-09 W: [1.0000603] b: [-0.00013645]\n",
      "step: 1680 cost: 2.437967e-09 W: [1.0000577] b: [-0.0001303]\n",
      "step: 1700 cost: 2.2282727e-09 W: [1.0000552] b: [-0.00012449]\n",
      "step: 1720 cost: 2.0343738e-09 W: [1.0000528] b: [-0.000119]\n",
      "step: 1740 cost: 1.8579319e-09 W: [1.0000504] b: [-0.00011374]\n",
      "step: 1760 cost: 1.6921019e-09 W: [1.000048] b: [-0.00010865]\n",
      "step: 1780 cost: 1.5384778e-09 W: [1.0000457] b: [-0.00010367]\n",
      "step: 1800 cost: 1.3959524e-09 W: [1.0000433] b: [-9.875852e-05]\n",
      "step: 1820 cost: 1.2580598e-09 W: [1.0000409] b: [-9.389399e-05]\n",
      "step: 1840 cost: 1.1398159e-09 W: [1.0000389] b: [-8.919993e-05]\n",
      "step: 1860 cost: 1.0302017e-09 W: [1.000037] b: [-8.4754996e-05]\n",
      "step: 1880 cost: 9.25791e-10 W: [1.0000352] b: [-8.055525e-05]\n",
      "step: 1900 cost: 8.4263857e-10 W: [1.0000335] b: [-7.659034e-05]\n",
      "step: 1920 cost: 7.560601e-10 W: [1.0000318] b: [-7.283922e-05]\n",
      "step: 1940 cost: 6.8421e-10 W: [1.0000304] b: [-6.9289155e-05]\n",
      "step: 1960 cost: 6.199012e-10 W: [1.000029] b: [-6.594135e-05]\n",
      "step: 1980 cost: 5.6417687e-10 W: [1.0000275] b: [-6.277914e-05]\n",
      "step: 2000 cost: 5.118288e-10 W: [1.0000262] b: [-5.9789756e-05]\n"
     ]
    }
   ],
   "source": [
    "# fit the line\n",
    "for step in range(2018):\n",
    "    sess.run(train)\n",
    "    if step % 20 == 0:\n",
    "        print(\"step:\", step, \"cost:\",sess.run(cost), \"W:\",sess.run(W), \"b:\",sess.run(b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## using placeholders in regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.set_random_seed(207)  # for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W = tf.Variable(tf.random_normal([1]), name='weight')\n",
    "b = tf.Variable(tf.random_normal([1]), name='bias')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, shape=[None])\n",
    "Y = tf.placeholder(tf.float32, shape=[None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Our hypothesis XW+b\n",
    "hypothesis = X * W + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# cost/loss function\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Minimize\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.01)\n",
    "train = optimizer.minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Launch the graph in a session.\n",
    "sess = tf.Session()\n",
    "# Initializes global variables in the graph.\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 5.8417726e-07 [1.9997112] [0.00201513]\n",
      "20 5.213185e-07 [1.9997269] [0.00190526]\n",
      "40 4.6628134e-07 [1.9997418] [0.0018014]\n",
      "60 4.17107e-07 [1.999756] [0.00170311]\n",
      "80 3.721331e-07 [1.9997692] [0.00161022]\n",
      "100 3.3347783e-07 [1.9997818] [0.00152243]\n",
      "120 2.9770248e-07 [1.9997936] [0.00143942]\n",
      "140 2.6583984e-07 [1.999805] [0.00136094]\n",
      "160 2.375031e-07 [1.9998155] [0.00128673]\n",
      "180 2.1233124e-07 [1.9998257] [0.00121655]\n",
      "200 1.899241e-07 [1.9998353] [0.00115012]\n",
      "220 1.696523e-07 [1.9998441] [0.00108735]\n",
      "240 1.5222304e-07 [1.9998528] [0.00102803]\n",
      "260 1.3562726e-07 [1.9998606] [0.00097195]\n",
      "280 1.2133448e-07 [1.9998683] [0.00091894]\n",
      "300 1.08465734e-07 [1.9998754] [0.00086883]\n",
      "320 9.714404e-08 [1.9998822] [0.00082148]\n",
      "340 8.680528e-08 [1.9998887] [0.00077675]\n",
      "360 7.757391e-08 [1.9998947] [0.00073442]\n",
      "380 6.9244074e-08 [1.9999006] [0.00069436]\n",
      "400 6.204118e-08 [1.999906] [0.00065643]\n",
      "420 5.5463413e-08 [1.9999111] [0.00062061]\n",
      "440 4.968054e-08 [1.999916] [0.00058674]\n",
      "460 4.421266e-08 [1.9999205] [0.00055466]\n",
      "480 3.94942e-08 [1.9999248] [0.00052442]\n",
      "500 3.5268766e-08 [1.999929] [0.00049582]\n",
      "520 3.1667998e-08 [1.9999329] [0.00046879]\n",
      "540 2.8258379e-08 [1.9999365] [0.00044322]\n",
      "560 2.5275236e-08 [1.99994] [0.00041906]\n",
      "580 2.2668019e-08 [1.9999433] [0.00039619]\n",
      "600 2.023838e-08 [1.9999464] [0.00037457]\n",
      "620 1.8045663e-08 [1.9999492] [0.00035412]\n",
      "640 1.606933e-08 [1.999952] [0.00033484]\n",
      "660 1.452554e-08 [1.9999547] [0.00031661]\n",
      "680 1.2920964e-08 [1.9999571] [0.00029934]\n",
      "700 1.1486994e-08 [1.9999595] [0.00028304]\n",
      "720 1.02109725e-08 [1.9999616] [0.00026759]\n",
      "740 9.217804e-09 [1.9999638] [0.00025303]\n",
      "760 8.207356e-09 [1.9999657] [0.00023923]\n",
      "780 7.359631e-09 [1.9999676] [0.00022618]\n",
      "800 6.5789814e-09 [1.9999694] [0.00021385]\n",
      "820 5.8768514e-09 [1.999971] [0.00020218]\n",
      "840 5.2320956e-09 [1.9999726] [0.00019118]\n",
      "860 4.69178e-09 [1.9999741] [0.00018076]\n",
      "880 4.2098236e-09 [1.9999754] [0.00017091]\n",
      "900 3.7255936e-09 [1.9999769] [0.00016161]\n",
      "920 3.3557324e-09 [1.9999781] [0.00015281]\n",
      "940 2.9889786e-09 [1.9999793] [0.00014449]\n",
      "960 2.669746e-09 [1.9999804] [0.00013662]\n",
      "980 2.4034914e-09 [1.9999814] [0.00012916]\n",
      "1000 2.173768e-09 [1.9999826] [0.00012214]\n",
      "1020 1.9024355e-09 [1.9999834] [0.00011546]\n",
      "1040 1.728722e-09 [1.9999844] [0.0001092]\n",
      "1060 1.553417e-09 [1.9999852] [0.00010325]\n",
      "1080 1.3785666e-09 [1.9999859] [9.760886e-05]\n",
      "1100 1.20599e-09 [1.9999866] [9.2290546e-05]\n",
      "1120 1.0917726e-09 [1.9999875] [8.725513e-05]\n",
      "1140 9.91425e-10 [1.9999882] [8.2534454e-05]\n",
      "1160 8.668242e-10 [1.9999888] [7.806809e-05]\n",
      "1180 7.70342e-10 [1.9999894] [7.3776544e-05]\n",
      "1200 6.8636535e-10 [1.99999] [6.9758404e-05]\n",
      "1220 6.1883537e-10 [1.9999905] [6.595963e-05]\n",
      "1240 5.608551e-10 [1.999991] [6.238017e-05]\n",
      "1260 4.89005e-10 [1.9999914] [5.9000977e-05]\n",
      "1280 4.630086e-10 [1.999992] [5.5809345e-05]\n",
      "1300 3.9328066e-10 [1.9999924] [5.277348e-05]\n",
      "1320 3.6986117e-10 [1.9999928] [4.9944243e-05]\n",
      "1340 3.1195668e-10 [1.9999932] [4.71913e-05]\n",
      "1360 3.014217e-10 [1.9999937] [4.466088e-05]\n",
      "1380 2.6746724e-10 [1.999994] [4.222265e-05]\n",
      "1400 2.2919266e-10 [1.9999943] [3.991476e-05]\n",
      "1420 2.0804691e-10 [1.9999945] [3.7797603e-05]\n",
      "1440 1.8493058e-10 [1.9999949] [3.5734487e-05]\n",
      "1460 1.5643309e-10 [1.9999951] [3.3738128e-05]\n",
      "1480 1.3892532e-10 [1.9999954] [3.202469e-05]\n",
      "1500 1.3339256e-10 [1.9999957] [3.0301722e-05]\n",
      "1520 1.1186785e-10 [1.999996] [2.8645509e-05]\n",
      "1540 1.06789834e-10 [1.9999962] [2.7094198e-05]\n",
      "1560 1.0125708e-10 [1.9999963] [2.5676401e-05]\n",
      "1580 8.799361e-11 [1.9999964] [2.4312643e-05]\n",
      "1600 7.738284e-11 [1.9999968] [2.2987035e-05]\n",
      "1620 7.101638e-11 [1.9999969] [2.1725004e-05]\n",
      "1640 5.7298166e-11 [1.999997] [2.0491581e-05]\n",
      "1660 5.7298166e-11 [1.9999973] [1.941711e-05]\n",
      "1680 4.880955e-11 [1.9999973] [1.8383957e-05]\n",
      "1700 4.5550525e-11 [1.9999976] [1.7408032e-05]\n",
      "1720 3.6379788e-11 [1.9999976] [1.6438458e-05]\n",
      "1740 3.342393e-11 [1.9999979] [1.5564261e-05]\n",
      "1760 2.7057467e-11 [1.9999979] [1.4702773e-05]\n",
      "1780 2.9482788e-11 [1.9999981] [1.3974797e-05]\n",
      "1800 2.5465852e-11 [1.9999981] [1.3157817e-05]\n",
      "1820 2.0008883e-11 [1.9999981] [1.253793e-05]\n",
      "1840 2.0918378e-11 [1.9999982] [1.1937112e-05]\n",
      "1860 2.0918378e-11 [1.9999983] [1.1368082e-05]\n",
      "1880 1.43245416e-11 [1.9999985] [1.0751371e-05]\n",
      "1900 1.6977234e-11 [1.9999986] [1.0166448e-05]\n",
      "1920 1.43245416e-11 [1.9999987] [9.622854e-06]\n",
      "1940 1.2732926e-11 [1.9999987] [9.104692e-06]\n",
      "1960 9.094947e-12 [1.9999987] [8.570637e-06]\n",
      "1980 9.094947e-12 [1.9999989] [8.062007e-06]\n",
      "2000 7.654914e-12 [1.9999989] [7.591525e-06]\n"
     ]
    }
   ],
   "source": [
    "# Fit the line\n",
    "for step in range(2018):\n",
    "    cost_val, W_val, b_val, _ =  sess.run([cost, W, b, train], feed_dict={X: [3, 6, 9], Y: [6, 12, 18]})\n",
    "    # list에 넣어서 한꺼번에 실행\n",
    "    # cost, W, b, train을 cost_val, W_val, b_val로 각각 저장\n",
    "    if step % 20 == 0:\n",
    "        print(step, cost_val, W_val, b_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10.000002]\n",
      "[14.]\n",
      "[ 4.0000052 15.999999 ]\n"
     ]
    }
   ],
   "source": [
    "# Testing our model\n",
    "print(sess.run(hypothesis, feed_dict={X: [5]}))\n",
    "print(sess.run(hypothesis, feed_dict={X: [7]}))\n",
    "print(sess.run(hypothesis, feed_dict={X: [2, 8]}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Minimize cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### simplify hypothesis\n",
    "- H(x) = Wx\n",
    "\n",
    "### Gradient descent algorithm = 경사하강법\n",
    "- minimize cost/loss function\n",
    "- Gradient descent is used many minimization problems\n",
    "- Cost(W, b) = given cost function -> find W, b to minimize cost\n",
    "- Cost(w1, w2 ....) w가 많은 경우에도 minimize 가능\n",
    "\n",
    "#### how find the lowest point?\n",
    "- 경사가 낮은 쪽으로 계속해서 내려가는 방법을 이용 = gradient descent algorithm\n",
    "\n",
    "#### how it work\n",
    "- start any other value\n",
    "- Keeping chaing W and b a little bit to try and reduce cost(W,b)\n",
    "- Each time you change the parameters, you select the gradient which reduces\n",
    "- cost(W, b) the most possible\n",
    "- Repeat\n",
    "- Do so until you converge to a local minimum\n",
    "- Has an interesting property\n",
    "   - Where you start can determine which minimum you end up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "tf.set_random_seed(207)  # for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = [1, 2, 3]\n",
    "Y = [1, 2, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W = tf.placeholder(tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Our hypothesis for linear model X * W\n",
    "hypothesis = X * W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# cost/loss function\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Launch the graph in a session.\n",
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Variables for plotting cost function\n",
    "W_history = []\n",
    "cost_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(-30, 50):\n",
    "    curr_W = i * 0.1 # W = -3 ~ 5\n",
    "    curr_cost = sess.run(cost, feed_dict={W: curr_W})\n",
    "    W_history.append(curr_W)\n",
    "    cost_history.append(curr_cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x151993ac438>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Show the cost function\n",
    "plt.plot(W_history, cost_history)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 2.758789 [1.4439104]\n",
      "1 0.7847223 [1.2367522]\n",
      "2 0.22320968 [1.1262678]\n",
      "3 0.063490935 [1.0673429]\n",
      "4 0.018059611 [1.0359162]\n",
      "5 0.005136938 [1.0191553]\n",
      "6 0.0014611592 [1.0102161]\n",
      "7 0.0004156183 [1.0054486]\n",
      "8 0.000118226926 [1.002906]\n",
      "9 3.3629163e-05 [1.0015498]\n",
      "10 9.5656815e-06 [1.0008266]\n",
      "11 2.7207086e-06 [1.0004408]\n",
      "12 7.736812e-07 [1.0002351]\n",
      "13 2.2018094e-07 [1.0001254]\n",
      "14 6.266221e-08 [1.0000669]\n",
      "15 1.7761025e-08 [1.0000356]\n",
      "16 5.0931703e-09 [1.0000191]\n",
      "17 1.4446897e-09 [1.0000101]\n",
      "18 4.0672887e-10 [1.0000054]\n",
      "19 1.1459633e-10 [1.0000029]\n",
      "20 3.474554e-11 [1.0000015]\n"
     ]
    }
   ],
   "source": [
    "x_data = [1, 2, 3,]\n",
    "y_data = [1, 2, 3,]\n",
    "\n",
    "W = tf.Variable(tf.random_normal([1]), name='weight')\n",
    "X = tf.placeholder(tf.float32)\n",
    "Y = tf.placeholder(tf.float32)\n",
    "\n",
    "# Out hypothesis Wx + b\n",
    "hypo = W * X\n",
    "\n",
    "# Cost(Loss) Function\n",
    "cost = tf.reduce_sum(tf.square(hypo - Y))\n",
    "\n",
    "learning_rate = 0.1\n",
    "gradient = tf.reduce_mean((W * X - Y) * X)\n",
    "descent = W - learning_rate * gradient\n",
    "update = W.assign(descent)\n",
    "\n",
    "sess = tf.Session()\n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for step in range(21):\n",
    "    sess.run(update, feed_dict={X: x_data, Y:y_data})\n",
    "    print(step, sess.run(cost, feed_dict={X: x_data, Y:y_data}), sess.run(W))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 5.0\n",
      "1 1.2666664\n",
      "2 1.0177778\n",
      "3 1.0011852\n",
      "4 1.000079\n",
      "5 1.0000052\n",
      "6 1.0000004\n",
      "7 1.0\n",
      "8 1.0\n",
      "9 1.0\n",
      "10 1.0\n",
      "11 1.0\n",
      "12 1.0\n",
      "13 1.0\n",
      "14 1.0\n",
      "15 1.0\n",
      "16 1.0\n",
      "17 1.0\n",
      "18 1.0\n",
      "19 1.0\n",
      "20 1.0\n",
      "21 1.0\n",
      "22 1.0\n",
      "23 1.0\n",
      "24 1.0\n",
      "25 1.0\n",
      "26 1.0\n",
      "27 1.0\n",
      "28 1.0\n",
      "29 1.0\n",
      "30 1.0\n",
      "31 1.0\n",
      "32 1.0\n",
      "33 1.0\n",
      "34 1.0\n",
      "35 1.0\n",
      "36 1.0\n",
      "37 1.0\n",
      "38 1.0\n",
      "39 1.0\n",
      "40 1.0\n",
      "41 1.0\n",
      "42 1.0\n",
      "43 1.0\n",
      "44 1.0\n",
      "45 1.0\n",
      "46 1.0\n",
      "47 1.0\n",
      "48 1.0\n",
      "49 1.0\n",
      "50 1.0\n",
      "51 1.0\n",
      "52 1.0\n",
      "53 1.0\n",
      "54 1.0\n",
      "55 1.0\n",
      "56 1.0\n",
      "57 1.0\n",
      "58 1.0\n",
      "59 1.0\n",
      "60 1.0\n",
      "61 1.0\n",
      "62 1.0\n",
      "63 1.0\n",
      "64 1.0\n",
      "65 1.0\n",
      "66 1.0\n",
      "67 1.0\n",
      "68 1.0\n",
      "69 1.0\n",
      "70 1.0\n",
      "71 1.0\n",
      "72 1.0\n",
      "73 1.0\n",
      "74 1.0\n",
      "75 1.0\n",
      "76 1.0\n",
      "77 1.0\n",
      "78 1.0\n",
      "79 1.0\n",
      "80 1.0\n",
      "81 1.0\n",
      "82 1.0\n",
      "83 1.0\n",
      "84 1.0\n",
      "85 1.0\n",
      "86 1.0\n",
      "87 1.0\n",
      "88 1.0\n",
      "89 1.0\n",
      "90 1.0\n",
      "91 1.0\n",
      "92 1.0\n",
      "93 1.0\n",
      "94 1.0\n",
      "95 1.0\n",
      "96 1.0\n",
      "97 1.0\n",
      "98 1.0\n",
      "99 1.0\n"
     ]
    }
   ],
   "source": [
    "# Lab 3 Minimizing Cost\n",
    "import tensorflow as tf\n",
    "tf.set_random_seed(207)  # for reproducibility\n",
    "\n",
    "# tf Graph Input\n",
    "X = [1, 2, 3]\n",
    "Y = [1, 2, 3]\n",
    "\n",
    "# Set wrong model weights\n",
    "W = tf.Variable(5.0)\n",
    "\n",
    "# Linear model\n",
    "hypothesis = X * W\n",
    "\n",
    "# cost/loss function\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - Y))\n",
    "\n",
    "# Minimize: Gradient Descent Magic\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.1)\n",
    "train = optimizer.minimize(cost)\n",
    "\n",
    "# Launch the graph in a session.\n",
    "sess = tf.Session()\n",
    "# Initializes global variables in the graph.\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for step in range(100):\n",
    "    print(step, sess.run(W))\n",
    "    sess.run(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [37.333332, 5.0, [(37.333336, 5.0)]]\n",
      "1 [33.84889, 4.6266665, [(33.84889, 4.6266665)]]\n",
      "2 [30.689657, 4.2881775, [(30.689657, 4.2881775)]]\n",
      "3 [27.825287, 3.9812808, [(27.825287, 3.9812808)]]\n",
      "4 [25.228262, 3.703028, [(25.228262, 3.703028)]]\n",
      "5 [22.873621, 3.4507453, [(22.873623, 3.4507453)]]\n",
      "6 [20.738752, 3.2220092, [(20.73875, 3.2220092)]]\n",
      "7 [18.803137, 3.0146217, [(18.803137, 3.0146217)]]\n",
      "8 [17.048176, 2.8265903, [(17.048176, 2.8265903)]]\n",
      "9 [15.457013, 2.6561086, [(15.457014, 2.6561086)]]\n",
      "10 [14.014359, 2.5015385, [(14.01436, 2.5015385)]]\n",
      "11 [12.706352, 2.361395, [(12.706352, 2.361395)]]\n",
      "12 [11.520427, 2.2343314, [(11.520427, 2.2343314)]]\n",
      "13 [10.445186, 2.119127, [(10.445185, 2.119127)]]\n",
      "14 [9.470302, 2.0146751, [(9.470302, 2.0146751)]]\n",
      "15 [8.586407, 1.9199722, [(8.586407, 1.9199722)]]\n",
      "16 [7.785009, 1.8341081, [(7.785009, 1.8341081)]]\n",
      "17 [7.0584083, 1.756258, [(7.0584083, 1.756258)]]\n",
      "18 [6.399624, 1.685674, [(6.399624, 1.685674)]]\n",
      "19 [5.8023257, 1.6216778, [(5.8023252, 1.6216778)]]\n",
      "20 [5.260776, 1.5636545, [(5.260776, 1.5636545)]]\n",
      "21 [4.7697697, 1.5110468, [(4.7697697, 1.5110468)]]\n",
      "22 [4.324591, 1.4633491, [(4.324591, 1.4633491)]]\n",
      "23 [3.9209633, 1.4201032, [(3.9209635, 1.4201032)]]\n",
      "24 [3.5550067, 1.3808936, [(3.5550067, 1.3808936)]]\n",
      "25 [3.2232056, 1.3453435, [(3.2232056, 1.3453435)]]\n",
      "26 [2.9223735, 1.3131114, [(2.9223735, 1.3131114)]]\n",
      "27 [2.6496189, 1.2838877, [(2.6496186, 1.2838877)]]\n",
      "28 [2.4023216, 1.2573916, [(2.4023216, 1.2573916)]]\n",
      "29 [2.178105, 1.2333684, [(2.178105, 1.2333684)]]\n",
      "30 [1.9748148, 1.2115873, [(1.9748147, 1.2115873)]]\n",
      "31 [1.7904993, 1.1918392, [(1.7904994, 1.1918392)]]\n",
      "32 [1.623386, 1.1739342, [(1.6233861, 1.1739342)]]\n",
      "33 [1.4718695, 1.1577003, [(1.4718695, 1.1577003)]]\n",
      "34 [1.3344955, 1.1429816, [(1.3344957, 1.1429816)]]\n",
      "35 [1.2099417, 1.1296366, [(1.2099419, 1.1296366)]]\n",
      "36 [1.0970144, 1.1175373, [(1.0970144, 1.1175373)]]\n",
      "37 [0.9946267, 1.1065671, [(0.9946267, 1.1065671)]]\n",
      "38 [0.90179497, 1.0966209, [(0.901795, 1.0966209)]]\n",
      "39 [0.8176275, 1.087603, [(0.81762755, 1.087603)]]\n",
      "40 [0.7413151, 1.0794266, [(0.7413151, 1.0794266)]]\n",
      "41 [0.67212623, 1.0720135, [(0.67212623, 1.0720135)]]\n",
      "42 [0.609394, 1.0652922, [(0.609394, 1.0652922)]]\n",
      "43 [0.5525169, 1.0591983, [(0.5525169, 1.0591983)]]\n",
      "44 [0.50094914, 1.0536731, [(0.50094914, 1.0536731)]]\n",
      "45 [0.45419374, 1.0486636, [(0.45419377, 1.0486636)]]\n",
      "46 [0.41180158, 1.0441216, [(0.41180158, 1.0441216)]]\n",
      "47 [0.37336722, 1.0400037, [(0.37336725, 1.0400037)]]\n",
      "48 [0.33851996, 1.03627, [(0.33852, 1.03627)]]\n",
      "49 [0.30692515, 1.0328848, [(0.30692515, 1.0328848)]]\n",
      "50 [0.27827826, 1.0298156, [(0.2782783, 1.0298156)]]\n",
      "51 [0.25230527, 1.0270327, [(0.25230527, 1.0270327)]]\n",
      "52 [0.2287569, 1.0245097, [(0.2287569, 1.0245097)]]\n",
      "53 [0.20740573, 1.022222, [(0.20740573, 1.022222)]]\n",
      "54 [0.18804836, 1.020148, [(0.18804836, 1.020148)]]\n",
      "55 [0.17049654, 1.0182675, [(0.17049655, 1.0182675)]]\n",
      "56 [0.15458433, 1.0165626, [(0.15458433, 1.0165626)]]\n",
      "57 [0.14015675, 1.0150168, [(0.14015675, 1.0150168)]]\n",
      "58 [0.12707591, 1.0136153, [(0.12707591, 1.0136153)]]\n",
      "59 [0.11521538, 1.0123445, [(0.11521538, 1.0123445)]]\n",
      "60 [0.10446167, 1.0111923, [(0.10446167, 1.0111923)]]\n",
      "61 [0.09471202, 1.0101477, [(0.09471202, 1.0101477)]]\n",
      "62 [0.08587202, 1.0092006, [(0.08587202, 1.0092006)]]\n",
      "63 [0.07785805, 1.0083419, [(0.07785805, 1.0083419)]]\n",
      "64 [0.07059129, 1.0075634, [(0.07059129, 1.0075634)]]\n",
      "65 [0.06400236, 1.0068574, [(0.06400236, 1.0068574)]]\n",
      "66 [0.05802846, 1.0062174, [(0.05802846, 1.0062174)]]\n",
      "67 [0.052612226, 1.005637, [(0.052612226, 1.005637)]]\n",
      "68 [0.047702473, 1.005111, [(0.047702473, 1.005111)]]\n",
      "69 [0.043249767, 1.0046339, [(0.043249767, 1.0046339)]]\n",
      "70 [0.03921318, 1.0042014, [(0.03921318, 1.0042014)]]\n",
      "71 [0.035553534, 1.0038093, [(0.035553537, 1.0038093)]]\n",
      "72 [0.032236177, 1.0034539, [(0.03223618, 1.0034539)]]\n",
      "73 [0.029227654, 1.0031315, [(0.029227655, 1.0031315)]]\n",
      "74 [0.02649951, 1.0028392, [(0.02649951, 1.0028392)]]\n",
      "75 [0.024025917, 1.0025742, [(0.024025917, 1.0025742)]]\n",
      "76 [0.021783749, 1.002334, [(0.02178375, 1.002334)]]\n",
      "77 [0.01975123, 1.0021162, [(0.019751232, 1.0021162)]]\n",
      "78 [0.017907381, 1.0019187, [(0.017907381, 1.0019187)]]\n",
      "79 [0.016236702, 1.0017396, [(0.016236704, 1.0017396)]]\n",
      "80 [0.014720838, 1.0015773, [(0.014720838, 1.0015773)]]\n",
      "81 [0.01334699, 1.00143, [(0.013346991, 1.00143)]]\n",
      "82 [0.012100856, 1.0012965, [(0.012100856, 1.0012965)]]\n",
      "83 [0.010971785, 1.0011755, [(0.010971785, 1.0011755)]]\n",
      "84 [0.0099481745, 1.0010659, [(0.0099481745, 1.0010659)]]\n",
      "85 [0.009018898, 1.0009663, [(0.009018898, 1.0009663)]]\n",
      "86 [0.008176883, 1.0008761, [(0.008176884, 1.0008761)]]\n",
      "87 [0.007413149, 1.0007943, [(0.007413149, 1.0007943)]]\n",
      "88 [0.006721576, 1.0007201, [(0.006721576, 1.0007201)]]\n",
      "89 [0.0060940585, 1.0006529, [(0.0060940585, 1.0006529)]]\n",
      "90 [0.005525271, 1.000592, [(0.0055252714, 1.000592)]]\n",
      "91 [0.0050098896, 1.0005368, [(0.0050098896, 1.0005368)]]\n",
      "92 [0.004542589, 1.0004867, [(0.004542589, 1.0004867)]]\n",
      "93 [0.0041189194, 1.0004413, [(0.0041189194, 1.0004413)]]\n",
      "94 [0.0037339528, 1.0004001, [(0.003733953, 1.0004001)]]\n",
      "95 [0.0033854644, 1.0003628, [(0.0033854644, 1.0003628)]]\n",
      "96 [0.0030694802, 1.0003289, [(0.0030694804, 1.0003289)]]\n",
      "97 [0.0027837753, 1.0002983, [(0.0027837753, 1.0002983)]]\n",
      "98 [0.0025234222, 1.0002704, [(0.0025234222, 1.0002704)]]\n",
      "99 [0.0022875469, 1.0002451, [(0.0022875469, 1.0002451)]]\n"
     ]
    }
   ],
   "source": [
    "# tf Graph Input\n",
    "X = [1, 2, 3]\n",
    "Y = [1, 2, 3]\n",
    "\n",
    "# Set wrong model weights\n",
    "W = tf.Variable(5.)\n",
    "\n",
    "# Linear model\n",
    "hypothesis = X * W\n",
    "\n",
    "# Manual gradient\n",
    "gradient = tf.reduce_mean((W * X - Y) * X) * 2\n",
    "\n",
    "# cost/loss function\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - Y))\n",
    "\n",
    "# Minimize: Gradient Descent Magic\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.01)\n",
    "train = optimizer.minimize(cost)\n",
    "\n",
    "# Get gradients\n",
    "gvs = optimizer.compute_gradients(cost, [W])\n",
    "# Optional: modify gradient if necessary\n",
    "# gvs = [(tf.clip_by_value(grad, -1., 1.), var) for grad, var in gvs]\n",
    "# Apply gradients\n",
    "apply_gradients = optimizer.apply_gradients(gvs)\n",
    "\n",
    "# Launch the graph in a session.\n",
    "sess = tf.Session()\n",
    "# Initializes global variables in the graph.\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for step in range(100):\n",
    "    print(step, sess.run([gradient, W, gvs]))\n",
    "    sess.run(apply_gradients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 122,
   "position": {
    "height": "40px",
    "left": "689px",
    "right": "20px",
    "top": "120px",
    "width": "250px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "none",
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
